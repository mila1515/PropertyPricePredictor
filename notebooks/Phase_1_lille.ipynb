{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58e7fbe0",
   "metadata": {},
   "source": [
    "## PrÃ©diction du Prix au mÂ² Ã  Lille\n",
    "\n",
    "###  Objectif\n",
    "\n",
    "Ã‰valuer diffÃ©rents modÃ¨les de machine learning pour prÃ©dire le **prix au mÂ²** de biens immobiliers Ã  Lille, en sÃ©parant l'analyse entre **maisons** et **appartements**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47766c9a",
   "metadata": {},
   "source": [
    "###  Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02613e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import pickle\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a46ce8b",
   "metadata": {},
   "source": [
    "### Chargement et filtrage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7930bfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Chargement des donnÃ©es\n",
    "df = pd.read_csv('../data/lille_2022.csv')\n",
    "\n",
    "# 2. Filtrer uniquement les biens avec 4 piÃ¨ces\n",
    "df = df[df['Nombre pieces principales'] == 4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26820bb",
   "metadata": {},
   "source": [
    "### SÃ©paration appartements/maisons + sÃ©lection des colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c84a0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. SÃ©parer appartements et maisons\n",
    "df_appart = df[df['Type local'] == 'Appartement'].copy()\n",
    "df_maison = df[df['Type local'] == 'Maison'].copy()\n",
    "\n",
    "# 4. Colonnes utiles\n",
    "colonnes_utiles = [\n",
    "    'Surface reelle bati',\n",
    "    'Nombre pieces principales',\n",
    "    'Type local',\n",
    "    'Surface terrain',\n",
    "    'Nombre de lots',\n",
    "    'Valeur fonciere'\n",
    "]\n",
    "df_appart = df_appart[colonnes_utiles].copy()\n",
    "df_maison = df_maison[colonnes_utiles].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365acd0d",
   "metadata": {},
   "source": [
    "### Nettoyage et crÃ©ation des variables\n",
    "\n",
    "- Nettoyage des donnÃ©es\n",
    "- CrÃ©ation de la variable cible prix_m2\n",
    "- Suppression des outliers via la mÃ©thode IQR (Interquartile Range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df917ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appartements aprÃ¨s nettoyage : 49\n",
      "Maisons aprÃ¨s nettoyage : 326\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # 5. ðŸ§¼ Traitement des valeurs manquantes\n",
    "# df_appart['Surface terrain'] = df_appart['Surface terrain'].fillna(0)\n",
    "# df_maison['Surface terrain'] = df_maison['Surface terrain'].fillna(df_maison['Surface terrain'].median())\n",
    "\n",
    "# 6. Nettoyage ciblÃ©\n",
    "df_appart.dropna(subset=colonnes_utiles, inplace=True)\n",
    "df_maison.dropna(subset=colonnes_utiles, inplace=True)\n",
    "\n",
    "# 7. CrÃ©ation de la variable cible\n",
    "df_appart['prix_m2'] = df_appart['Valeur fonciere'] / df_appart['Surface reelle bati']\n",
    "df_maison['prix_m2'] = df_maison['Valeur fonciere'] / df_maison['Surface reelle bati']\n",
    "\n",
    "# 8. Suppression des valeurs aberrantes via IQR\n",
    "def clean_outliers_iqr(df, colonne='prix_m2'):\n",
    "    Q1 = df[colonne].quantile(0.25)\n",
    "    Q3 = df[colonne].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    borne_inf = Q1 - 1.5 * IQR\n",
    "    borne_sup = Q3 + 1.5 * IQR\n",
    "    return df[(df[colonne] >= borne_inf) & (df[colonne] <= borne_sup)]\n",
    "\n",
    "df_appart = clean_outliers_iqr(df_appart)\n",
    "df_maison = clean_outliers_iqr(df_maison)\n",
    "\n",
    "print(f'Appartements aprÃ¨s nettoyage : {len(df_appart)}')\n",
    "print(f'Maisons aprÃ¨s nettoyage : {len(df_maison)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3578d4c",
   "metadata": {},
   "source": [
    "### Fonction dâ€™entraÃ®nement et sÃ©lection de modÃ¨les\n",
    "Contient une grosse fonction modele_pipeline() qui :\n",
    "\n",
    "- SÃ©pare X (features) et y (cible)\n",
    "- Applique une standardisation\n",
    "- EntraÃ®ne plusieurs modÃ¨les : LinearRegression, DecisionTree, RandomForest, XGBoost\n",
    "- Optimise DecisionTree et RandomForest avec GridSearchCV\n",
    "- Retourne un DataFrame des rÃ©sultats (MSE, RMSE, RÂ²)\n",
    "- Enfin, un tableau comparatif des performances est crÃ©Ã©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66f086c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Comparatif global des performances des modÃ¨les (Appartements & Maisons) :\n",
      "\n",
      "                                Type    MSE   RMSE     R2\n",
      "ModÃ¨le                                                   \n",
      "RandomForest            Appartements  0.216  0.464  0.731\n",
      "RandomForest_Optimized  Appartements  0.216  0.464  0.731\n",
      "XGBoost                 Appartements  0.317  0.563  0.605\n",
      "DecisionTree            Appartements  0.454  0.674  0.434\n",
      "DecisionTree_Optimized  Appartements  0.633  0.796  0.212\n",
      "LinearRegression        Appartements  0.867  0.931 -0.080\n",
      "LinearRegression             Maisons  0.865  0.930  0.022\n",
      "DecisionTree_Optimized       Maisons  1.020  1.010 -0.153\n",
      "RandomForest_Optimized       Maisons  1.071  1.035 -0.210\n",
      "RandomForest                 Maisons  1.140  1.068 -0.289\n",
      "XGBoost                      Maisons  1.412  1.188 -0.596\n",
      "DecisionTree                 Maisons  2.171  1.473 -1.454\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ================================\n",
    "# 1. Fonction d'entraÃ®nement avec encodage Type local\n",
    "# ================================\n",
    "def modele_pipeline(df, label, save_scaler_prefix=None):\n",
    "    # Colonnes numÃ©riques\n",
    "    X_num = df[['Surface reelle bati', 'Nombre de lots', 'Surface terrain']]\n",
    "    # Encodage one-hot de 'Type local' (ex: Maison = 1, Appartement = 0)\n",
    "    X_cat = pd.get_dummies(df['Type local'], drop_first=True)\n",
    "    # ConcatÃ©nation\n",
    "    X = pd.concat([X_num, X_cat], axis=1)\n",
    "\n",
    "    y = df['prix_m2']\n",
    "\n",
    "    # Split train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # --- SCALING ---\n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "    y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "    y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "    # Sauvegarde des scalers si demandÃ©\n",
    "    if save_scaler_prefix is not None:\n",
    "        joblib.dump(scaler_X, f\"../models/scaler_X_{save_scaler_prefix}.pkl\")\n",
    "        joblib.dump(scaler_y, f\"../models/scaler_y_{save_scaler_prefix}.pkl\")\n",
    "\n",
    "    models = {\n",
    "        'LinearRegression': LinearRegression(),\n",
    "        'DecisionTree': DecisionTreeRegressor(random_state=42),\n",
    "        'RandomForest': RandomForestRegressor(random_state=42)\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    trained_models = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_scaled, y_train_scaled)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        mse = mean_squared_error(y_test_scaled, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test_scaled, y_pred)\n",
    "        results[name] = {'MSE': mse, 'RMSE': rmse, 'R2': r2}\n",
    "        trained_models[name] = model\n",
    "\n",
    "    # DecisionTree OptimisÃ©\n",
    "    tree_params = {'max_depth': [2, 4, 6, 8, 10]}\n",
    "    grid_tree = GridSearchCV(DecisionTreeRegressor(random_state=42), tree_params, cv=5)\n",
    "    grid_tree.fit(X_train_scaled, y_train_scaled)\n",
    "    best_tree = grid_tree.best_estimator_\n",
    "    y_pred = best_tree.predict(X_test_scaled)\n",
    "    results['DecisionTree_Optimized'] = {\n",
    "        'MSE': mean_squared_error(y_test_scaled, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test_scaled, y_pred)),\n",
    "        'R2': r2_score(y_test_scaled, y_pred)\n",
    "    }\n",
    "    trained_models['DecisionTree_Optimized'] = best_tree\n",
    "\n",
    "    # RandomForest OptimisÃ©\n",
    "    rf_params = {'n_estimators': [50, 100], 'max_depth': [None, 10, 20]}\n",
    "    grid_rf = GridSearchCV(RandomForestRegressor(random_state=42), rf_params, cv=5)\n",
    "    grid_rf.fit(X_train_scaled, y_train_scaled)\n",
    "    best_rf = grid_rf.best_estimator_\n",
    "    y_pred = best_rf.predict(X_test_scaled)\n",
    "    results['RandomForest_Optimized'] = {\n",
    "        'MSE': mean_squared_error(y_test_scaled, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test_scaled, y_pred)),\n",
    "        'R2': r2_score(y_test_scaled, y_pred)\n",
    "    }\n",
    "    trained_models['RandomForest_Optimized'] = best_rf\n",
    "\n",
    "    # XGBoost\n",
    "    xgb = XGBRegressor(random_state=42, verbosity=0)\n",
    "    xgb.fit(X_train_scaled, y_train_scaled)\n",
    "    y_pred = xgb.predict(X_test_scaled)\n",
    "    results['XGBoost'] = {\n",
    "        'MSE': mean_squared_error(y_test_scaled, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test_scaled, y_pred)),\n",
    "        'R2': r2_score(y_test_scaled, y_pred)\n",
    "    }\n",
    "    trained_models['XGBoost'] = xgb\n",
    "\n",
    "    # RÃ©sumÃ© en DataFrame\n",
    "    df_resultats = pd.DataFrame(results).T\n",
    "    df_resultats = df_resultats[['MSE', 'RMSE', 'R2']]\n",
    "    df_resultats.index.name = 'ModÃ¨le'\n",
    "    df_resultats['Type'] = label.split(' - ')[0]  # Exemple: \\\"Appartements\\\" ou \\\"Maisons\\\" ou \\\"Global\\\"\n",
    "\n",
    "    return results, trained_models, df_resultats\n",
    "\n",
    "# Sinon, entraÃ®nement sÃ©parÃ© :\n",
    "resultats_appart, models_appart, df_appart_resultats = modele_pipeline(df_appart, \"Appartements - Lille\", save_scaler_prefix=\"appart\")\n",
    "resultats_maison, models_maison, df_maison_resultats = modele_pipeline(df_maison, \"Maisons - Lille\", save_scaler_prefix=\"maison\")\n",
    "\n",
    "# ================================\n",
    "# 3. Comparatif global\n",
    "# ================================\n",
    "df_comparatif = pd.concat([df_appart_resultats, df_maison_resultats])\n",
    "df_comparatif = df_comparatif[['Type', 'MSE', 'RMSE', 'R2']]\n",
    "df_comparatif_sorted = df_comparatif.sort_values(by=['Type', 'R2'], ascending=[True, False])\n",
    "\n",
    "print(\"\\nðŸ“Š Comparatif global des performances des modÃ¨les (Appartements & Maisons) :\\n\")\n",
    "print(df_comparatif_sorted.round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3c54d3",
   "metadata": {},
   "source": [
    "###  Analyse de la PrÃ©diction du Prix au mÂ² Ã  Lille\n",
    "\n",
    "\n",
    "Le **meilleur modÃ¨le** pour la prÃ©diction du **prix au mÂ² Ã  Lille** est celui qui prÃ©sente :\n",
    "\n",
    "- le **plus petit MSE** (Mean Squared Error),\n",
    "- et le **plus grand RÂ²**.\n",
    "---\n",
    "\n",
    "####  Analyse â€“ Maisons\n",
    "\n",
    "\n",
    "#####  Meilleur ModÃ¨le : `LinearRegression`\n",
    "\n",
    "- **RÂ² le plus Ã©levÃ©** : 0.022 (seul modÃ¨le avec un RÂ² positif)\n",
    "- **RMSE le plus bas** : 0.930\n",
    "- Les modÃ¨les complexes ne font **pas mieux**, ce qui indique des **donnÃ©es insuffisantes**\n",
    "\n",
    "##### InterprÃ©tation\n",
    "\n",
    "> Tous les modÃ¨les (sauf LinearRegression) ont un **RÂ² nÃ©gatif**, donc **moins performants que la moyenne**.  \n",
    "> Cela suggÃ¨re que les **caractÃ©ristiques des maisons sont trop hÃ©tÃ©rogÃ¨nes** pour Ãªtre bien captÃ©es sans donnÃ©es supplÃ©mentaires.\n",
    "\n",
    "---\n",
    "\n",
    "###  Analyse â€“ Appartements\n",
    "\n",
    "\n",
    "\n",
    "####  Meilleur ModÃ¨le : `RandomForest`\n",
    "\n",
    "- **RÂ² trÃ¨s Ã©levÃ©** : 0.731 â†’ trÃ¨s bon pouvoir prÃ©dictif\n",
    "- **Robuste et performant** sans trop de tuning\n",
    "- Le modÃ¨le optimisÃ© nâ€™apporte pas de gain â†’ les paramÃ¨tres par dÃ©faut sont suffisants\n",
    "\n",
    "---\n",
    "\n",
    "###  Comparatif GÃ©nÃ©ral : Appartements vs Maisons\n",
    "\n",
    "\n",
    "- **Appartements** : bonnes performances, modÃ¨les efficaces\n",
    "- **Maisons** : rÃ©sultats trÃ¨s faibles â†’ manque d'information pour prÃ©dire correctement\n",
    "\n",
    "---\n",
    "\n",
    "### Recommandations\n",
    "\n",
    "#### Pour amÃ©liorer les performances :\n",
    "\n",
    "- **Ajouter des variables** : quartier, code postal, annÃ©e de construction, Ã©tage, Ã©tat du bien, Ã©quipements\n",
    "- Faire du **feature engineering** (crÃ©ation de nouvelles variables dÃ©rivÃ©es)\n",
    "- Appliquer une **analyse spatiale** (gÃ©olocalisation, proximitÃ©)\n",
    "- CrÃ©er des **clusters de maisons** (moderne vs ancien, petite vs grande)\n",
    "\n",
    "#### Pour les maisons :\n",
    "\n",
    "- SÃ©parer par type ou style de bien\n",
    "- Utiliser des mÃ©thodes robustes aux faibles volumes (modÃ¨les bayÃ©siens, KNN)\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "- Le modÃ¨le **Random Forest** est **trÃ¨s performant sur les appartements** (RÂ² = 0.73)\n",
    "- Le modÃ¨le **LinearRegression est le seul valable pour les maisons**, mais reste faible (RÂ² = 0.02)\n",
    "- La **qualitÃ© des prÃ©dictions est directement liÃ©e Ã  la richesse des donnÃ©es disponibles**\n",
    "- Ajouter des donnÃ©es gÃ©ographiques (quartier, carte)\n",
    "- IntÃ©grer des caractÃ©ristiques prÃ©cises (annÃ©e, jardin, Ã©tat)\n",
    "\n",
    ">  **Prochaine Ã©tape : enrichir les donnÃ©es** pour mieux modÃ©liser les maisons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f879840",
   "metadata": {},
   "source": [
    "### Sauvegarde du modÃ¨le global\n",
    "\n",
    "Objectif : conserver toute lâ€™analyse en un seul bundle (modÃ¨les, scalers, rÃ©sultats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7088dd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bundle Lille (tous modÃ¨les, scalers, features, rÃ©sultats, meilleurs modÃ¨les) sauvegardÃ© dans : '../models/model_lille.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# RÃ©cupÃ©ration des meilleurs modÃ¨les\n",
    "best_model_appart = models_appart['RandomForest']\n",
    "best_model_maison = models_maison['LinearRegression']\n",
    "\n",
    "# Chargement des scalers sauvegardÃ©s\n",
    "scaler_X_appart = joblib.load('../models/scaler_X_appart.pkl')\n",
    "scaler_y_appart = joblib.load('../models/scaler_y_appart.pkl')\n",
    "scaler_X_maison = joblib.load('../models/scaler_X_maison.pkl')\n",
    "scaler_y_maison = joblib.load('../models/scaler_y_maison.pkl')\n",
    "\n",
    "# RÃ©sultats de validation pour les meilleurs modÃ¨les\n",
    "best_results_appart = resultats_appart['RandomForest']\n",
    "best_results_maison = resultats_maison['LinearRegression']\n",
    "\n",
    "# Features utilisÃ©es\n",
    "features = ['Surface reelle bati', 'Nombre de lots', 'Surface terrain'] + list(pd.get_dummies(df['Type local'], drop_first=True).columns)\n",
    "\n",
    "# Dictionnaire Ã  sauvegarder\n",
    "lille_bundle = {\n",
    "    'models_appart': models_appart,  # tous les modÃ¨les appartements\n",
    "    'models_maison': models_maison,  # tous les modÃ¨les maisons\n",
    "    'best_model_appart': best_model_appart,\n",
    "    'best_model_maison': best_model_maison,\n",
    "    'scaler_X_appart': scaler_X_appart,\n",
    "    'scaler_y_appart': scaler_y_appart,\n",
    "    'scaler_X_maison': scaler_X_maison,\n",
    "    'scaler_y_maison': scaler_y_maison,\n",
    "    'features': features,\n",
    "    'results_appart': resultats_appart,  # tous les rÃ©sultats appartements\n",
    "    'results_maison': resultats_maison,  # tous les rÃ©sultats maisons\n",
    "    'best_results_appart': best_results_appart,\n",
    "    'best_results_maison': best_results_maison\n",
    "}\n",
    "\n",
    "with open('../models/model_lille.pkl', 'wb') as f:\n",
    "    pickle.dump(lille_bundle, f)\n",
    "\n",
    "print(\"âœ… Bundle Lille (tous modÃ¨les, scalers, features, rÃ©sultats, meilleurs modÃ¨les) sauvegardÃ© dans : '../models/model_lille.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e069f4df",
   "metadata": {},
   "source": [
    "### CrÃ©ation dâ€™un bundle allÃ©gÃ© avec juste les meilleurs modÃ¨les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b5bda5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bundle Lille (meilleurs modÃ¨les, scalers, features, rÃ©sultats) sauvegardÃ© dans : '../models/model_lille_best.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# RÃ©cupÃ©ration des meilleurs modÃ¨les\n",
    "best_model_appart = models_appart['RandomForest']\n",
    "best_model_maison = models_maison['LinearRegression']\n",
    "\n",
    "# Chargement des scalers sauvegardÃ©s\n",
    "scaler_X_appart = joblib.load('../models/scaler_X_appart.pkl')\n",
    "scaler_y_appart = joblib.load('../models/scaler_y_appart.pkl')\n",
    "scaler_X_maison = joblib.load('../models/scaler_X_maison.pkl')\n",
    "scaler_y_maison = joblib.load('../models/scaler_y_maison.pkl')\n",
    "\n",
    "# RÃ©sultats de validation pour les meilleurs modÃ¨les\n",
    "best_results_appart = resultats_appart['RandomForest']\n",
    "best_results_maison = resultats_maison['LinearRegression']\n",
    "\n",
    "# Features utilisÃ©es\n",
    "features = ['Surface reelle bati', 'Nombre de lots', 'Surface terrain'] + list(pd.get_dummies(df['Type local'], drop_first=True).columns)\n",
    "\n",
    "# Dictionnaire Ã  sauvegarder\n",
    "lille_bundle = {\n",
    "    'model_appart': best_model_appart,\n",
    "    'model_maison': best_model_maison,\n",
    "    'scaler_X_appart': scaler_X_appart,\n",
    "    'scaler_y_appart': scaler_y_appart,\n",
    "    'scaler_X_maison': scaler_X_maison,\n",
    "    'scaler_y_maison': scaler_y_maison,\n",
    "    'features': features,\n",
    "    'results_appart': best_results_appart,\n",
    "    'results_maison': best_results_maison\n",
    "}\n",
    "\n",
    "with open('../models/model_lille_best.pkl', 'wb') as f:\n",
    "    pickle.dump(lille_bundle, f)\n",
    "\n",
    "print(\"âœ… Bundle Lille (meilleurs modÃ¨les, scalers, features, rÃ©sultats) sauvegardÃ© dans : '../models/model_lille_best.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
