{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58e7fbe0",
   "metadata": {},
   "source": [
    "## Pr√©diction du Prix au m¬≤ √† Lille\n",
    "\n",
    "###  Objectif\n",
    "\n",
    "√âvaluer diff√©rents mod√®les de machine learning pour pr√©dire le **prix au m¬≤** de biens immobiliers √† Lille, en s√©parant l'analyse entre **maisons** et **appartements**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47766c9a",
   "metadata": {},
   "source": [
    "###  Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02613e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import pickle\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a46ce8b",
   "metadata": {},
   "source": [
    "### Chargement et filtrage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7930bfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Chargement des donn√©es\n",
    "df = pd.read_csv('../data/lille_2022.csv')\n",
    "\n",
    "# 2. Filtrer uniquement les biens avec 4 pi√®ces\n",
    "df = df[df['Nombre pieces principales'] == 4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26820bb",
   "metadata": {},
   "source": [
    "### S√©paration appartements/maisons + s√©lection des colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c84a0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. S√©parer appartements et maisons\n",
    "df_appart = df[df['Type local'] == 'Appartement'].copy()\n",
    "df_maison = df[df['Type local'] == 'Maison'].copy()\n",
    "\n",
    "# 4. Colonnes utiles\n",
    "colonnes_utiles = [\n",
    "    'Surface reelle bati',\n",
    "    'Nombre pieces principales',\n",
    "    'Type local',\n",
    "    'Surface terrain',\n",
    "    'Nombre de lots',\n",
    "    'Valeur fonciere'\n",
    "]\n",
    "df_appart = df_appart[colonnes_utiles].copy()\n",
    "df_maison = df_maison[colonnes_utiles].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365acd0d",
   "metadata": {},
   "source": [
    "### Nettoyage et cr√©ation des variables\n",
    "\n",
    "- Nettoyage des donn√©es\n",
    "- Cr√©ation de la variable cible prix_m2\n",
    "- Suppression des outliers via la m√©thode IQR (Interquartile Range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df917ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appartements apr√®s nettoyage : 49\n",
      "Maisons apr√®s nettoyage : 326\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # 5. üßº Traitement des valeurs manquantes\n",
    "# df_appart['Surface terrain'] = df_appart['Surface terrain'].fillna(0)\n",
    "# df_maison['Surface terrain'] = df_maison['Surface terrain'].fillna(df_maison['Surface terrain'].median())\n",
    "\n",
    "# 6. Nettoyage cibl√©\n",
    "df_appart.dropna(subset=colonnes_utiles, inplace=True)\n",
    "df_maison.dropna(subset=colonnes_utiles, inplace=True)\n",
    "\n",
    "# 7. Cr√©ation de la variable cible\n",
    "df_appart['prix_m2'] = df_appart['Valeur fonciere'] / df_appart['Surface reelle bati']\n",
    "df_maison['prix_m2'] = df_maison['Valeur fonciere'] / df_maison['Surface reelle bati']\n",
    "\n",
    "# 8. Suppression des valeurs aberrantes via IQR\n",
    "def clean_outliers_iqr(df, colonne='prix_m2'):\n",
    "    Q1 = df[colonne].quantile(0.25)\n",
    "    Q3 = df[colonne].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    borne_inf = Q1 - 1.5 * IQR\n",
    "    borne_sup = Q3 + 1.5 * IQR\n",
    "    return df[(df[colonne] >= borne_inf) & (df[colonne] <= borne_sup)]\n",
    "\n",
    "df_appart = clean_outliers_iqr(df_appart)\n",
    "df_maison = clean_outliers_iqr(df_maison)\n",
    "\n",
    "print(f'Appartements apr√®s nettoyage : {len(df_appart)}')\n",
    "print(f'Maisons apr√®s nettoyage : {len(df_maison)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3578d4c",
   "metadata": {},
   "source": [
    "### Fonction d‚Äôentra√Ænement et s√©lection de mod√®les\n",
    "Contient une grosse fonction modele_pipeline() qui :\n",
    "\n",
    "- S√©pare X (features) et y (cible)\n",
    "- Applique une standardisation\n",
    "- Entra√Æne plusieurs mod√®les : LinearRegression, DecisionTree, RandomForest, XGBoost\n",
    "- Optimise DecisionTree et RandomForest avec GridSearchCV\n",
    "- Retourne un DataFrame des r√©sultats (MSE, RMSE, R¬≤)\n",
    "- Enfin, un tableau comparatif des performances est cr√©√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66f086c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Comparatif global des performances des mod√®les (Appartements & Maisons) :\n",
      "\n",
      "                                Type    MSE   RMSE     R2\n",
      "Mod√®le                                                   \n",
      "RandomForest            Appartements  0.216  0.464  0.731\n",
      "RandomForest_Optimized  Appartements  0.216  0.464  0.731\n",
      "XGBoost                 Appartements  0.317  0.563  0.605\n",
      "DecisionTree            Appartements  0.454  0.674  0.434\n",
      "DecisionTree_Optimized  Appartements  0.633  0.796  0.212\n",
      "LinearRegression        Appartements  0.867  0.931 -0.080\n",
      "LinearRegression             Maisons  0.865  0.930  0.022\n",
      "DecisionTree_Optimized       Maisons  1.020  1.010 -0.153\n",
      "RandomForest_Optimized       Maisons  1.071  1.035 -0.210\n",
      "RandomForest                 Maisons  1.140  1.068 -0.289\n",
      "XGBoost                      Maisons  1.412  1.188 -0.596\n",
      "DecisionTree                 Maisons  2.171  1.473 -1.454\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ================================\n",
    "# 1. Fonction d'entra√Ænement avec encodage Type local\n",
    "# ================================\n",
    "def modele_pipeline(df, label, save_scaler_prefix=None):\n",
    "    # Colonnes num√©riques\n",
    "    X_num = df[['Surface reelle bati', 'Nombre de lots', 'Surface terrain']]\n",
    "    # Encodage one-hot de 'Type local' (ex: Maison = 1, Appartement = 0)\n",
    "    X_cat = pd.get_dummies(df['Type local'], drop_first=True)\n",
    "    # Concat√©nation\n",
    "    X = pd.concat([X_num, X_cat], axis=1)\n",
    "\n",
    "    y = df['prix_m2']\n",
    "\n",
    "    # Split train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # --- SCALING ---\n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "    y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "    y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "    # Sauvegarde des scalers si demand√©\n",
    "    if save_scaler_prefix is not None:\n",
    "        joblib.dump(scaler_X, f\"../models/scaler_X_{save_scaler_prefix}.pkl\")\n",
    "        joblib.dump(scaler_y, f\"../models/scaler_y_{save_scaler_prefix}.pkl\")\n",
    "\n",
    "    models = {\n",
    "        'LinearRegression': LinearRegression(),\n",
    "        'DecisionTree': DecisionTreeRegressor(random_state=42),\n",
    "        'RandomForest': RandomForestRegressor(random_state=42)\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    trained_models = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_scaled, y_train_scaled)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        mse = mean_squared_error(y_test_scaled, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test_scaled, y_pred)\n",
    "        results[name] = {'MSE': mse, 'RMSE': rmse, 'R2': r2}\n",
    "        trained_models[name] = model\n",
    "\n",
    "    # DecisionTree Optimis√©\n",
    "    tree_params = {'max_depth': [2, 4, 6, 8, 10]}\n",
    "    grid_tree = GridSearchCV(DecisionTreeRegressor(random_state=42), tree_params, cv=5)\n",
    "    grid_tree.fit(X_train_scaled, y_train_scaled)\n",
    "    best_tree = grid_tree.best_estimator_\n",
    "    y_pred = best_tree.predict(X_test_scaled)\n",
    "    results['DecisionTree_Optimized'] = {\n",
    "        'MSE': mean_squared_error(y_test_scaled, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test_scaled, y_pred)),\n",
    "        'R2': r2_score(y_test_scaled, y_pred)\n",
    "    }\n",
    "    trained_models['DecisionTree_Optimized'] = best_tree\n",
    "\n",
    "    # RandomForest Optimis√©\n",
    "    rf_params = {'n_estimators': [50, 100], 'max_depth': [None, 10, 20]}\n",
    "    grid_rf = GridSearchCV(RandomForestRegressor(random_state=42), rf_params, cv=5)\n",
    "    grid_rf.fit(X_train_scaled, y_train_scaled)\n",
    "    best_rf = grid_rf.best_estimator_\n",
    "    y_pred = best_rf.predict(X_test_scaled)\n",
    "    results['RandomForest_Optimized'] = {\n",
    "        'MSE': mean_squared_error(y_test_scaled, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test_scaled, y_pred)),\n",
    "        'R2': r2_score(y_test_scaled, y_pred)\n",
    "    }\n",
    "    trained_models['RandomForest_Optimized'] = best_rf\n",
    "\n",
    "    # XGBoost\n",
    "    xgb = XGBRegressor(random_state=42, verbosity=0)\n",
    "    xgb.fit(X_train_scaled, y_train_scaled)\n",
    "    y_pred = xgb.predict(X_test_scaled)\n",
    "    results['XGBoost'] = {\n",
    "        'MSE': mean_squared_error(y_test_scaled, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test_scaled, y_pred)),\n",
    "        'R2': r2_score(y_test_scaled, y_pred)\n",
    "    }\n",
    "    trained_models['XGBoost'] = xgb\n",
    "\n",
    "    # R√©sum√© en DataFrame\n",
    "    df_resultats = pd.DataFrame(results).T\n",
    "    df_resultats = df_resultats[['MSE', 'RMSE', 'R2']]\n",
    "    df_resultats.index.name = 'Mod√®le'\n",
    "    df_resultats['Type'] = label.split(' - ')[0]  # Exemple: \\\"Appartements\\\" ou \\\"Maisons\\\" ou \\\"Global\\\"\n",
    "\n",
    "    return results, trained_models, df_resultats\n",
    "\n",
    "# Sinon, entra√Ænement s√©par√© :\n",
    "resultats_appart, models_appart, df_appart_resultats = modele_pipeline(df_appart, \"Appartements - Lille\", save_scaler_prefix=\"appart\")\n",
    "resultats_maison, models_maison, df_maison_resultats = modele_pipeline(df_maison, \"Maisons - Lille\", save_scaler_prefix=\"maison\")\n",
    "\n",
    "# ================================\n",
    "# 3. Comparatif global\n",
    "# ================================\n",
    "df_comparatif = pd.concat([df_appart_resultats, df_maison_resultats])\n",
    "df_comparatif = df_comparatif[['Type', 'MSE', 'RMSE', 'R2']]\n",
    "df_comparatif_sorted = df_comparatif.sort_values(by=['Type', 'R2'], ascending=[True, False])\n",
    "\n",
    "print(\"\\nüìä Comparatif global des performances des mod√®les (Appartements & Maisons) :\\n\")\n",
    "print(df_comparatif_sorted.round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3c54d3",
   "metadata": {},
   "source": [
    "###  Analyse de la Pr√©diction du Prix au m¬≤ √† Lille\n",
    "\n",
    "\n",
    "Le **meilleur mod√®le** pour la pr√©diction du **prix au m¬≤ √† Lille** est celui qui pr√©sente :\n",
    "\n",
    "- le **plus petit MSE** (Mean Squared Error),\n",
    "- et le **plus grand R¬≤**.\n",
    "---\n",
    "\n",
    "####  Analyse ‚Äì Maisons\n",
    "\n",
    "\n",
    "#####  Meilleur Mod√®le : `LinearRegression`\n",
    "\n",
    "- **R¬≤ le plus √©lev√©** : 0.022 (seul mod√®le avec un R¬≤ positif)\n",
    "- **RMSE le plus bas** : 0.930\n",
    "- Les mod√®les complexes ne font **pas mieux**, ce qui indique des **donn√©es insuffisantes**\n",
    "\n",
    "##### Interpr√©tation\n",
    "\n",
    "> Tous les mod√®les (sauf LinearRegression) ont un **R¬≤ n√©gatif**, donc **moins performants que la moyenne**.  \n",
    "> Cela sugg√®re que les **caract√©ristiques des maisons sont trop h√©t√©rog√®nes** pour √™tre bien capt√©es sans donn√©es suppl√©mentaires.\n",
    "\n",
    "---\n",
    "\n",
    "###  Analyse ‚Äì Appartements\n",
    "\n",
    "\n",
    "\n",
    "####  Meilleur Mod√®le : `RandomForest`\n",
    "\n",
    "- **R¬≤ tr√®s √©lev√©** : 0.731 ‚Üí tr√®s bon pouvoir pr√©dictif\n",
    "- **Robuste et performant** sans trop de tuning\n",
    "- Le mod√®le optimis√© n‚Äôapporte pas de gain ‚Üí les param√®tres par d√©faut sont suffisants\n",
    "\n",
    "---\n",
    "\n",
    "###  Comparatif G√©n√©ral : Appartements vs Maisons\n",
    "\n",
    "\n",
    "- **Appartements** : bonnes performances, mod√®les efficaces\n",
    "- **Maisons** : r√©sultats tr√®s faibles ‚Üí manque d'information pour pr√©dire correctement\n",
    "\n",
    "---\n",
    "\n",
    "### Recommandations\n",
    "\n",
    "#### Pour am√©liorer les performances :\n",
    "\n",
    "- **Ajouter des variables** : quartier, code postal, ann√©e de construction, √©tage, √©tat du bien, √©quipements\n",
    "- Faire du **feature engineering** (cr√©ation de nouvelles variables d√©riv√©es)\n",
    "- Appliquer une **analyse spatiale** (g√©olocalisation, proximit√©)\n",
    "- Cr√©er des **clusters de maisons** (moderne vs ancien, petite vs grande)\n",
    "\n",
    "#### Pour les maisons :\n",
    "\n",
    "- S√©parer par type ou style de bien\n",
    "- Utiliser des m√©thodes robustes aux faibles volumes (mod√®les bay√©siens, KNN)\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "- Le mod√®le **Random Forest** est **tr√®s performant sur les appartements** (R¬≤ = 0.73)\n",
    "- Le mod√®le **LinearRegression est le seul valable pour les maisons**, mais reste faible (R¬≤ = 0.02)\n",
    "- La **qualit√© des pr√©dictions est directement li√©e √† la richesse des donn√©es disponibles**\n",
    "- Ajouter des donn√©es g√©ographiques (quartier, carte)\n",
    "- Int√©grer des caract√©ristiques pr√©cises (ann√©e, jardin, √©tat)\n",
    "\n",
    ">  **Prochaine √©tape : enrichir les donn√©es** pour mieux mod√©liser les maisons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f879840",
   "metadata": {},
   "source": [
    "### Sauvegarde du mod√®le global\n",
    "\n",
    "Objectif : conserver toute l‚Äôanalyse en un seul bundle (mod√®les, scalers, r√©sultats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7088dd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bundle Lille (tous mod√®les, scalers, features, r√©sultats, meilleurs mod√®les) sauvegard√© dans : '../models/model_lille.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# R√©cup√©ration des meilleurs mod√®les\n",
    "best_model_appart = models_appart['RandomForest']\n",
    "best_model_maison = models_maison['LinearRegression']\n",
    "\n",
    "# Chargement des scalers sauvegard√©s\n",
    "scaler_X_appart = joblib.load('../models/scaler_X_appart.pkl')\n",
    "scaler_y_appart = joblib.load('../models/scaler_y_appart.pkl')\n",
    "scaler_X_maison = joblib.load('../models/scaler_X_maison.pkl')\n",
    "scaler_y_maison = joblib.load('../models/scaler_y_maison.pkl')\n",
    "\n",
    "# R√©sultats de validation pour les meilleurs mod√®les\n",
    "best_results_appart = resultats_appart['RandomForest']\n",
    "best_results_maison = resultats_maison['LinearRegression']\n",
    "\n",
    "# Features utilis√©es\n",
    "features = ['Surface reelle bati', 'Nombre de lots', 'Surface terrain'] + list(pd.get_dummies(df['Type local'], drop_first=True).columns)\n",
    "\n",
    "# Dictionnaire √† sauvegarder\n",
    "lille_bundle = {\n",
    "    'models_appart': models_appart,  # tous les mod√®les appartements\n",
    "    'models_maison': models_maison,  # tous les mod√®les maisons\n",
    "    'best_model_appart': best_model_appart,\n",
    "    'best_model_maison': best_model_maison,\n",
    "    'scaler_X_appart': scaler_X_appart,\n",
    "    'scaler_y_appart': scaler_y_appart,\n",
    "    'scaler_X_maison': scaler_X_maison,\n",
    "    'scaler_y_maison': scaler_y_maison,\n",
    "    'features': features,\n",
    "    'results_appart': resultats_appart,  # tous les r√©sultats appartements\n",
    "    'results_maison': resultats_maison,  # tous les r√©sultats maisons\n",
    "    'best_results_appart': best_results_appart,\n",
    "    'best_results_maison': best_results_maison\n",
    "}\n",
    "\n",
    "with open('../models/model_lille.pkl', 'wb') as f:\n",
    "    pickle.dump(lille_bundle, f)\n",
    "\n",
    "print(\"‚úÖ Bundle Lille (tous mod√®les, scalers, features, r√©sultats, meilleurs mod√®les) sauvegard√© dans : '../models/model_lille.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e069f4df",
   "metadata": {},
   "source": [
    "### Cr√©ation d‚Äôun bundle all√©g√© avec juste les meilleurs mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b5bda5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bundle Lille (meilleurs mod√®les, scalers, features, r√©sultats) sauvegard√© dans : '../models/model_lille_best.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# R√©cup√©ration des meilleurs mod√®les\n",
    "best_model_appart = models_appart['RandomForest']\n",
    "best_model_maison = models_maison['LinearRegression']\n",
    "\n",
    "# Chargement des scalers sauvegard√©s\n",
    "scaler_X_appart = joblib.load('../models/scaler_X_appart.pkl')\n",
    "scaler_y_appart = joblib.load('../models/scaler_y_appart.pkl')\n",
    "scaler_X_maison = joblib.load('../models/scaler_X_maison.pkl')\n",
    "scaler_y_maison = joblib.load('../models/scaler_y_maison.pkl')\n",
    "\n",
    "# R√©sultats de validation pour les meilleurs mod√®les\n",
    "best_results_appart = resultats_appart['RandomForest']\n",
    "best_results_maison = resultats_maison['LinearRegression']\n",
    "\n",
    "# Features utilis√©es\n",
    "features = ['Surface reelle bati', 'Nombre de lots', 'Surface terrain'] + list(pd.get_dummies(df['Type local'], drop_first=True).columns)\n",
    "\n",
    "# Dictionnaire √† sauvegarder\n",
    "lille_bundle = {\n",
    "    'model_appart': best_model_appart,\n",
    "    'model_maison': best_model_maison,\n",
    "    'scaler_X_appart': scaler_X_appart,\n",
    "    'scaler_y_appart': scaler_y_appart,\n",
    "    'scaler_X_maison': scaler_X_maison,\n",
    "    'scaler_y_maison': scaler_y_maison,\n",
    "    'features': features,\n",
    "    'results_appart': best_results_appart,\n",
    "    'results_maison': best_results_maison\n",
    "}\n",
    "\n",
    "with open('../models/model_lille_best.pkl', 'wb') as f:\n",
    "    pickle.dump(lille_bundle, f)\n",
    "\n",
    "print(\"‚úÖ Bundle Lille (meilleurs mod√®les, scalers, features, r√©sultats) sauvegard√© dans : '../models/model_lille_best.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
